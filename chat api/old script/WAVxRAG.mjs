// Text prompt -> Gemini audio reply; saves each turn as WAV
import { GoogleGenAI, Modality, Type } from "@google/genai";
import dotenv from "dotenv";
import readline from "node:readline";
import Speaker from "speaker";
import { WebSocket } from "ws";
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { Document } from "@langchain/core/documents";
import { MongoClient } from "mongodb";

dotenv.config();

// Ensure @google/genai has a WebSocket implementation in Node
if (!globalThis.WebSocket) {
  globalThis.WebSocket = WebSocket;
}

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  console.error("Missing GEMINI_API_KEY in environment");
  process.exit(1);
}

const ai = new GoogleGenAI({ apiKey: GEMINI_API_KEY });
// Use the specific model requested by the user
const model = "gemini-2.5-flash-native-audio-preview-09-2025";

// --- RAG Setup ---
// --- RAG Setup ---
let warrantyVectorStore;
let priceVectorStore;
let serviceVectorStore;

async function initializeRAG() {
  console.log("Initializing RAG Vector Stores...");
  const warrantyData = [
    "à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸´à¸™à¸„à¹‰à¸² A: à¸£à¸±à¸šà¸›à¸£à¸°à¸à¸±à¸™ 2 à¸›à¸µ à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚: à¸•à¹‰à¸­à¸‡à¹€à¸à¹‡à¸šà¹ƒà¸šà¹€à¸ªà¸£à¹‡à¸ˆà¹„à¸§à¹‰",
    "à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸´à¸™à¸„à¹‰à¸² B: à¸£à¸±à¸šà¸›à¸£à¸°à¸à¸±à¸™ 1 à¸›à¸µ à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚: à¹„à¸¡à¹ˆà¸„à¸¸à¹‰à¸¡à¸„à¸£à¸­à¸‡à¸­à¸¸à¸šà¸±à¸•à¸´à¹€à¸«à¸•à¸¸",
    "à¸›à¸£à¸°à¸à¸±à¸™à¸ªà¸´à¸™à¸„à¹‰à¸² C: à¸£à¸±à¸šà¸›à¸£à¸°à¸à¸±à¸™ 3 à¸›à¸µ à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚: à¸šà¸£à¸´à¸à¸²à¸£à¸‹à¹ˆà¸­à¸¡à¸–à¸¶à¸‡à¸šà¹‰à¸²à¸™à¸Ÿà¸£à¸µ",
  ];
  const priceData = [
    "à¸£à¸²à¸„à¸²à¸ªà¸´à¸™à¸„à¹‰à¸² A: 50,000 à¸šà¸²à¸—",
    "à¸£à¸²à¸„à¸²à¸ªà¸´à¸™à¸„à¹‰à¸² B: 30,000 à¸šà¸²à¸—",
    "à¸£à¸²à¸„à¸²à¸ªà¸´à¸™à¸„à¹‰à¸² C: 80,000 à¸šà¸²à¸—",
  ];
  const serviceData = ["à¸¨à¸¹à¸™à¸¢à¹Œà¸šà¸£à¸´à¸à¸²à¸£: à¹€à¸›à¸´à¸”à¸—à¸³à¸à¸²à¸£ à¸ˆà¸±à¸™à¸—à¸£à¹Œ-à¸¨à¸¸à¸à¸£à¹Œ 09:00 - 18:00 à¸™."];

  const docs = warrantyData.map((text) => new Document({ pageContent: text }));
  const priceDocs = priceData.map(
    (text) => new Document({ pageContent: text })
  );
  const serviceDocs = serviceData.map(
    (text) => new Document({ pageContent: text })
  );

  const embeddings = new GoogleGenerativeAIEmbeddings({
    apiKey: GEMINI_API_KEY,
    modelName: "text-embedding-004",
  });

  // Initialize separate stores
  warrantyVectorStore = await MemoryVectorStore.fromDocuments(docs, embeddings);
  priceVectorStore = await MemoryVectorStore.fromDocuments(
    priceDocs,
    embeddings
  );
  serviceVectorStore = await MemoryVectorStore.fromDocuments(
    serviceDocs,
    embeddings
  );

  console.log("RAG Vector Stores Ready.");
}

// --- Tool Definitions ---

const SearchWarrantyTool = {
  name: "search_warranty",
  description: "Search for warranty information.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      query: {
        type: Type.STRING,
        description: "The search query about warranty",
      },
    },
    required: ["query"],
  },
};

const SearchPriceTool = {
  name: "search_price",
  description: "Search for price information.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      query: {
        type: Type.STRING,
        description: "The search query about price.",
      },
    },
    required: ["query"],
  },
};
const SearchServiceTool = {
  name: "search_service",
  description: "Search for service information.",
  parameters: {
    type: Type.OBJECT,
    properties: {
      query: {
        type: Type.STRING,
        description: "The search query about service.",
      },
    },
    required: ["query"],
  },
};

const config = {
  responseModalities: [Modality.AUDIO],
  systemInstruction:
    "You are a trustworthy assistant. Answer politely. If you need to access warranty data, call 'search_warranty' and use the retrieved information to answer. If you want to access price data, call 'search_price'. If you want to access service data, call 'search_service'. ALWAYS use the relevant tool whenever a related question is asked. IMPORTANT: When you get the result from a tool, YOU MUST READ the retrieved information out loud to the user clearly. à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸šà¸­à¸à¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥",
  tools: [
    {
      functionDeclarations: [
        SearchWarrantyTool,
        SearchPriceTool,
        SearchServiceTool,
      ],
    },
  ],
};

// Debug log when the model triggers a function call/tool call
function logFunctionCalls(message) {
  const calls = [];

  const toolCalls = message?.toolCall?.functionCalls;
  if (Array.isArray(toolCalls)) {
    calls.push(...toolCalls);
  }

  const parts = message?.serverContent?.modelTurn?.parts || [];
  for (const part of parts) {
    if (part?.functionCall) {
      calls.push(part.functionCall);
    }
  }

  if (!calls.length) {
    return;
  }

  for (const call of calls) {
    const argString = safeStringifyArgs(call?.args);
    const idLabel = call?.id ? ` id=${call.id}` : "";
    const nameLabel = call?.name ? ` name=${call.name}` : "";
    console.log(`[function_call]${idLabel}${nameLabel} args=${argString}`);
  }
}

function safeStringifyArgs(args) {
  try {
    return JSON.stringify(args ?? {});
  } catch (err) {
    return `[unserializable args: ${err?.message ?? err}]`;
  }
}

// Send function responses so the model can use tool outputs to reply
async function handleFunctionCalls(session, message) {
  const toolCalls = message?.toolCall?.functionCalls;
  if (!Array.isArray(toolCalls) || toolCalls.length === 0) {
    return;
  }

  for (const call of toolCalls) {
    const args = call?.args ?? {};
    const argString = safeStringifyArgs(args);
    console.log(
      `[function_response] id=${call?.id ?? "n/a"} name=${
        call?.name ?? "n/a"
      } response=${argString}`
    );

    let result = "No information found.";
    let searchResults = [];

    if (call.name === "search_warranty") {
      console.log(`ðŸ” Searching Warranty for: ${args.query}`);
      searchResults = await warrantyVectorStore.similaritySearchWithScore(
        args.query,
        1
      );
    } else if (call.name === "search_price") {
      console.log(`ðŸ” Searching Price for: ${args.query}`);
      searchResults = await priceVectorStore.similaritySearchWithScore(
        args.query,
        1
      );
    } else if (call.name === "search_service") {
      console.log(`ðŸ” Searching Service for: ${args.query}`);
      searchResults = await serviceVectorStore.similaritySearchWithScore(
        args.query,
        1
      );
    }

    if (searchResults.length > 0) {
      const [doc, score] = searchResults[0];
      console.log(`ðŸ“Š Similarity Score: ${score}`);
      // Threshold: 0.7 (Increased to avoid false positives like J -> B)
      if (score >= 0.7) {
        result = doc.pageContent;
        console.log(`ðŸ“„ Found: ${result}`);
      } else {
        console.log("âŒ Score too low, returning 'No information found.'");
      }
    }

    await session.sendToolResponse({
      functionResponses: [
        {
          id: call?.id,
          name: call?.name,
          response: { result },
        },
      ],
    });
  }
}

async function live() {
  await initializeRAG();

  const responseQueue = [];

  async function waitMessage() {
    let message;
    while (!message) {
      message = responseQueue.shift();
      if (!message) {
        await new Promise((resolve) => setTimeout(resolve, 100));
      }
    }
    return message;
  }

  async function handleTurn() {
    const turns = [];
    let done = false;
    while (!done) {
      const message = await waitMessage();
      turns.push(message);

      // Debug log
      const hasToolCall =
        message?.toolCall?.functionCalls?.length > 0 ||
        message?.serverContent?.modelTurn?.parts?.some((p) => p.functionCall);

      if (hasToolCall) {
        console.log("âš¡ Received Tool Call message");
        done = true;
      } else if (message.serverContent && message.serverContent.turnComplete) {
        done = true;
      }
    }
    return turns;
  }

  const session = await ai.live.connect({
    model,
    callbacks: {
      onopen: () => console.log("âœ… Session opened"),
      onmessage: async (message) => {
        logFunctionCalls(message);
        responseQueue.push(message);
      },
      onerror: (e) => {
        console.error("Error:", e.message);
      },
      onclose: (e) => {
        console.log("ðŸ”» Session closed:", e.reason);
      },
    },
    config,
  });

  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const askUser = (query) =>
    new Promise((resolve) => {
      rl.question(query, (answer) => resolve(answer));
    });

  let turnIndex = 1;
  console.log("ðŸ’¬ à¸žà¸´à¸¡à¸žà¹Œà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸„à¸¸à¸¢à¸à¸±à¸š AI à¹„à¸”à¹‰à¹€à¸¥à¸¢ (à¸žà¸´à¸¡à¸žà¹Œ 'exit' à¹€à¸žà¸·à¹ˆà¸­à¸­à¸­à¸)");

  let running = true;
  while (running) {
    const userInput = await askUser("à¸„à¸¸à¸“: ");

    if (!userInput.trim()) {
      continue;
    }

    if (userInput.toLowerCase() === "exit") {
      running = false;
      break;
    }

    // Send text input to the model
    session.sendRealtimeInput({
      text: userInput,
    });

    console.log("ðŸ¤– à¸à¸³à¸¥à¸±à¸‡à¸£à¸­à¸„à¸³à¸•à¸­à¸š (audio)...");

    let turns = await handleTurn();

    // Check if the turn involved a tool call
    let toolCallMsg = turns.find((msg) => {
      return (
        msg?.toolCall?.functionCalls?.length > 0 ||
        msg?.serverContent?.modelTurn?.parts?.some((p) => p.functionCall)
      );
    });

    while (toolCallMsg) {
      console.log(
        "ðŸ¤– Model called a tool, executing and waiting for next turn..."
      );
      await handleFunctionCalls(session, toolCallMsg);

      const nextTurns = await handleTurn();
      turns = turns.concat(nextTurns);

      // Check if the new turn is ALSO a tool call (chained calls)
      toolCallMsg = nextTurns.find((msg) => {
        return (
          msg?.toolCall?.functionCalls?.length > 0 ||
          msg?.serverContent?.modelTurn?.parts?.some((p) => p.functionCall)
        );
      });
    }

    // Check for text content (debug)
    const textParts = turns
      .map((t) =>
        t?.serverContent?.modelTurn?.parts?.map((p) => p.text).join("")
      )
      .filter((t) => t);
    if (textParts.length > 0) {
      console.log("ðŸ“ Text response:", textParts.join(" "));
    }

    // Combine returned audio
    const combinedAudio = turns.reduce((acc, turn) => {
      if (turn.data) {
        const buffer = Buffer.from(turn.data, "base64");
        const intArray = new Int16Array(
          buffer.buffer,
          buffer.byteOffset,
          buffer.byteLength / Int16Array.BYTES_PER_ELEMENT
        );
        return acc.concat(Array.from(intArray));
      }
      return acc;
    }, []);

    if (combinedAudio.length === 0) {
      console.log("âš  à¹„à¸¡à¹ˆà¸¡à¸µ audio à¸à¸¥à¸±à¸šà¸¡à¸²à¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸™à¸£à¸­à¸šà¸™à¸µà¹‰");
      continue;
    }

    const audioBuffer = new Int16Array(combinedAudio);
    playAudio(Buffer.from(audioBuffer.buffer), 24000);
  }

  rl.close();
  session.close();
}

async function main() {
  await live().catch((e) => console.error("got error", e));
}

main();

function playAudio(pcmBuffer, sampleRate) {
  const speaker = new Speaker({
    channels: 1,
    bitDepth: 16,
    sampleRate,
    signed: true,
  });
  speaker.write(pcmBuffer);
  speaker.end();
}
